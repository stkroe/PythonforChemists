[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Analysis and Visualization for Chemists and Material Scientists",
    "section": "",
    "text": "Overview\nWelcome to the Data Analysis and Visualization Course for Chemists and Material Scientists! This course is designed for better understanding how Python can be used for data analysis and visualization in the fields of chemistry and materials science. Before diving into the course content, please take a moment to review the following important informations.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#who-is-the-course-for",
    "href": "index.html#who-is-the-course-for",
    "title": "Data Analysis and Visualization for Chemists and Material Scientists",
    "section": "Who is the course for?",
    "text": "Who is the course for?\nThis course has been designed for persons who are looking to undertake a specialised data visualization and analyzing course in Python with a particular focus the field of chemistry and materials science. The course tries to be interactivley with practical examples.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#what-can-you-expect-from-this-course",
    "href": "index.html#what-can-you-expect-from-this-course",
    "title": "Data Analysis and Visualization for Chemists and Material Scientists",
    "section": "What can you expect from this course",
    "text": "What can you expect from this course\n\nThis course wants to show you the advantage of using a programming language for data analyzing and visualization in chemistry and material science in comparision to gui-based softwares.\nThe course will give you a very brief introduction to Python and its libraries.\nThe main focus will be on the libraries numpy, pandas, pandas, scipy, matplotlib and seaborn for data analyzing and visualization.\nThe course is organized interactivly. You will get the chance to practice with exercises.\nUpon successful completion of this course, participants will have acquired a comprehensive understanding of the fundamental components of Python and the key packages necessary for the analysis and presentation of their own research data.\nYou can test your knowledge by an exam example at the end of this course.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#what-can-you-not-expect-from-this-course",
    "href": "index.html#what-can-you-not-expect-from-this-course",
    "title": "Data Analysis and Visualization for Chemists and Material Scientists",
    "section": "What can you NOT expect from this course",
    "text": "What can you NOT expect from this course\n\nYou will not get a deep explanation of the Python language. Please consider full Python tutorials for get a deep overview of Python.\nYou will not learn object-oriented programming in Python.\nWe will not go into details of the libraries.\nThis is not a statistics course.\n\nThe aim of this course should be that you get an idea how Python can be use for data analyzing and visualization in chemistry and material science field.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#how-this-course-is-structured",
    "href": "index.html#how-this-course-is-structured",
    "title": "Data Analysis and Visualization for Chemists and Material Scientists",
    "section": "How this course is structured",
    "text": "How this course is structured\nThis course is divided into three possible paths to accomplish the learning objectives:\n\nBeginner Path: Focuses on first contact with Python, covering basic concepts and introductory modules.\nAdvanced Path: Provides a deeper dive into different libraries and specialized visualization plots.\nChallenging Path: Explores advanced topics and complex data visualization techniques, with more difficult exercises and in-depth analysis.\n\nEach lecture includes examples related to chemistry and material science. At the end of each part, there are exercises to test your understanding and reinforce the concepts learned. These exercises are designed to be practical and relevant to real-world scenarios in chemistry and materials science.\nComprehensive Exam\nAt the very end of the course, there is a comprehensive exam which covers a complete data analyis and visualization example.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#this-course-within-of-the-vu-data-science-and-visualization-primer-for-chemists-and-material-scientists",
    "href": "index.html#this-course-within-of-the-vu-data-science-and-visualization-primer-for-chemists-and-material-scientists",
    "title": "Data Analysis and Visualization for Chemists and Material Scientists",
    "section": "This course within of the “VU Data Science and Visualization Primer for Chemists and Material Scientists”",
    "text": "This course within of the “VU Data Science and Visualization Primer for Chemists and Material Scientists”\nWe concentrate on the Basic Path during this lecture.\nTimeschedule for a week table\n\n\n\n\n\n\n\n\n\n\n\nTime\nMonday\nTuesday\nWednesday\nThursday\nFriday\n\n\n\n\n13:00-14:00\nIntroduction/Python Basics\nLecture 2\nLecture 3\nLecture 4\nLecture 5\n\n\n14:00-15:00\nLecture 1\nLecture 2\nLecture 3\nLecture 4\nExample 5\n\n\n15:00-16:00\nLecture 1\nExample 2\nExample 3\nExample 4\nF&Q\n\n\n16:00-17:00\nExample 1\nExample 2\nExample 3\nExample 4\nFinal Exam\n\n\n17:00-18:00\nExample 1\nExample 2\nExample 3\nExample 4\nFinal Exam",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/Introduction.html",
    "href": "course/chapters/Introduction/Lecture0/Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "What do you need for data analysis and visualization?\nA very simple approach would be the use of basic spreadsheet programs with graphical user interfaces e.g. Excel, LibreOffice Calc …\nBut for more advanced analysis you need probably specifc plotting and analysis tools:\nThis is a small election of tools, that can be used for data analysis and plotting.\nFor a larger list see these wikipedia lists:",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/Introduction.html#what-do-you-need-for-data-analysis-and-visualization",
    "href": "course/chapters/Introduction/Lecture0/Introduction.html#what-do-you-need-for-data-analysis-and-visualization",
    "title": "Introduction",
    "section": "",
    "text": "Scientists produce a lot of data which needs to be analyzed and visualized.\nClear presentation of data is essential for the understanding the data.\nIt helps to improve your scientific communication and make your results more accessible to others.\nThere are many tools available for data analysis and visualization.\n\n\n\n\nYou can either use programs with GUIs e.g. LabPlot, QtiPlot, Scilab, SciDAVis, Origin …\nor a GUI based program with command line interface e.g. Xmgrace, GNU Octave …\nor command line based tools e.g. Gnuplot, Matlab, Mathematica …\nor programming languages e.g. Python, R, Julia …\n\n\n\n\nList of Numerical Analysis Software\nList of Graphical Software\nList of Statistical Software\nList of Computer Algebra Systems",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/WhatIsPython.html",
    "href": "course/chapters/Introduction/Lecture0/WhatIsPython.html",
    "title": "Python?",
    "section": "",
    "text": "Short History of Python\n(see Wikipedia for more details)\nVan Rossum designed Python as a “Computer Programming Language for Everybody”.",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python?</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/WhatIsPython.html#short-history-of-python",
    "href": "course/chapters/Introduction/Lecture0/WhatIsPython.html#short-history-of-python",
    "title": "Python?",
    "section": "",
    "text": "1989: the beginning of python\n1991: Guido van Rossum, a Dutch programmer and father of Python, implemented and published the first version of Python.\nFun fact: The name Python came from the show Monty Python’s Flying Circus.\n1994: Python 1.0 was released\n2000: Python 2.0 was released\n2008: Python 3.0 was released with new syntax and features\nImportant: python3 to python2 is backward incompatible e.g. print(\"Hello World\") python3 and print \"Hello World\" python2.\npython2 is nowdays outdated. It is not recommended to use it for new projects.",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python?</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/WhatIsPython.html#what-is-python",
    "href": "course/chapters/Introduction/Lecture0/WhatIsPython.html#what-is-python",
    "title": "Python?",
    "section": "What is Python?",
    "text": "What is Python?\n\nPython is an interpreted language in comparsion to compiled languages e.g. C or C++\nPython is often slower compare to compiled languages\nPython has dynamically type-check and a garabge collection\nPython is also able to object-oriented and functional programming\nPython is a high-level language, which means that it is closer to human language than machine language which the computer is understanding\n\n\nSimple Scheme how Python works internally:\nSo if you execute a python programe, the python interpreter will convert the code into byte code and then the byte code will be executed by the python virtual machine (PVM).",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python?</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/WhatIsPython.html#how-i-can-learn-python",
    "href": "course/chapters/Introduction/Lecture0/WhatIsPython.html#how-i-can-learn-python",
    "title": "Python?",
    "section": "How I can learn Python?",
    "text": "How I can learn Python?\nThere are a lot of resources to dive deeper into Python e.g.:\n\nhttps://www.py4e.com/ (Python for Everybody)\nhttps://py-tutorial-de.readthedocs.io/de/python-3.3/ (German Tutorial)\nhttps://www.w3schools.com/python/default.asp\nhttps://jakevdp.github.io/PythonDataScienceHandbook/\nhttps://exercism.org/ (Coding Exercises)\nhttps://www.freecodecamp.org/ (Coding Exercises)\nhttps://realpython.com/tutorials/data-viz/\nhttps://www.youtube.com/watch?v=LHBE6Q9XlzI\n\n\n\n\n\n\n\nImportant\n\n\n\nAs it is with languages, you can only learn it if you practicing it.  So, start you own projects and have fun with it!",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python?</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/InstallationGuide.html",
    "href": "course/chapters/Introduction/Lecture0/InstallationGuide.html",
    "title": "Installation Guide",
    "section": "",
    "text": "How to install Python locally?\nHere is a short instruction how to install Python on your local PC or you can use Google Colab to solve all the exercises of this course.\nFundamental Python websites:",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Installation Guide</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/InstallationGuide.html#install-python-interpreter",
    "href": "course/chapters/Introduction/Lecture0/InstallationGuide.html#install-python-interpreter",
    "title": "Installation Guide",
    "section": "1. Install Python Interpreter",
    "text": "1. Install Python Interpreter\nYour preferred searching engine is your friend to find the best way to install Python on your system. Please choose that method which is suitable for you.\nPython can be install by severals ways:\n\ndirectly by Python official site\n\nthe installation guide can be found under python wiki\n\nor via package manager of your os:\n\ne.g.: sudo apt install python (linux debian) or brew install python (macOS)\n\nor via docker, wsl ect.\nor via a conda or mamba python package and environment managers which have a python interpreter on board and are avaiable for Windows, Linux and macOS [my recomendation]",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Installation Guide</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/InstallationGuide.html#python-package-and-environment-manager",
    "href": "course/chapters/Introduction/Lecture0/InstallationGuide.html#python-package-and-environment-manager",
    "title": "Installation Guide",
    "section": "2. Python Package and Environment manager",
    "text": "2. Python Package and Environment manager\nThe advantage of using a python package and environment manager is that you have a python interpreter directly on board but you can also directly create different python enviroments and install and remove python packages.\n\nConda\nThere are differerent condainstaller: (Please pay attention which one is suitable for you (https://docs.anaconda.com/distro-or-miniconda/).\n\n\n\n\n\n\nWarning\n\n\n\nPlease read the Anaconda Terms of Service FAQs and Terms of Service) not every case is free of use.\n\n\n\nAnaconda Distribution is a comprehensive distribution which includes conda and hundreds of preinstalled packages and tools.\nminiconda is the light version of it which contains only conda, python interpreter and few fundamental packages\nminiforge minimal installer for conda and using only the community conda-forge channel\n\n\n\nMamba\nAnother python package and environment managers is mamba. mamba is a reimplementation of conda: - micromamba is a statically linked version of mamba - mambaand it at the moment faster than conda\n\n\n\n\n\n\nTip\n\n\n\nRecommondation: micromamba  \nInstall it like it is explained under the micromamba documentation: - https://mamba.readthedocs.io/en/latest/installation/micromamba-installation.html\n\n\nPlease install in one of the above explained ways Python and use your preferred searching enging to get more information.",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Installation Guide</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/InstallationGuide.html#set-up-an-environment",
    "href": "course/chapters/Introduction/Lecture0/InstallationGuide.html#set-up-an-environment",
    "title": "Installation Guide",
    "section": "3. Set up an environment",
    "text": "3. Set up an environment\nIt is often very useful to have different python enviroments for different python projects because of the need of different python package versions.\nYou can use conda or micromamba to create different environments. There exists also other virtual environment manager.\nIn this course the explaination is restricted to micromamba as an example. If you want to use something else there exists tons of information online how to use other programs.\n\nMicromamba: Most important commands are:\nRead for more detail: https://mamba.readthedocs.io/en/latest/user_guide/micromamba.html\nCreating a new virtual environment:\nmicromamba create --name &lt;myenvname&gt;\nInstall new packages:\nmicromamba install &lt;packagename&gt;\nList all environments:\nmicromamba env list\nActivate an environment:\nmicromamba activate &lt;myenvname&gt;\nList all packages of this environment:\nmicromamba list",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Installation Guide</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/InstallationGuide.html#usefull-packages-for-data-analyse-and-visualization",
    "href": "course/chapters/Introduction/Lecture0/InstallationGuide.html#usefull-packages-for-data-analyse-and-visualization",
    "title": "Installation Guide",
    "section": "4. Usefull packages for Data Analyse and Visualization:",
    "text": "4. Usefull packages for Data Analyse and Visualization:\n\nmatplotlib - data visualization library\nnumpy - numerical library\nscipy - scientific library\npandas - data manipulation library\nseaborn - data visualization library\nscikit-learn - machine learning library\nstatsmodels - statistical library\njupyter-notebook/jupyterlab - interactive computing environment\nipykernel - IPython Kernel for Jupyter\npip - package installer for python instead of conda\n\n\n\n\n\n\n\nTip\n\n\n\nRecommendation  Use yml-file with all needed packages and configurations:\n\n\nSave this in a environment.yml file:\nname: myenv\nchannels:\n - conda-forge\ndependencies:\n - python=3.12\n - pandas\n - numpy\n - matplotlib\n - jupyterlab\n - scikit-learn\n - scipy\n - pip\n - ipykernel\n - seaborn\n - statsmodels\nand create an environment with this specific packages:\nmicromamba env create -f environment.yml\nTest your installation by opening the interactive python mode by typing in your terminal (Linux, macOS) / comand prompt (Windows):\npython\nthen something like this should be opened in your terminal (Linux, macOS) / comand prompt (Windows)\nPython 3.12.7 | packaged by conda-forge | (main, Oct  4 2024, 15:57:01) [Clang 17.0.6 ] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; \nthen type:\nprint(\"Hello World!\")\nIf this works your installation was successful!",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Installation Guide</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/InstallationGuide.html#choose-an-editor",
    "href": "course/chapters/Introduction/Lecture0/InstallationGuide.html#choose-an-editor",
    "title": "Installation Guide",
    "section": "5. Choose an editor",
    "text": "5. Choose an editor\nAfter you installed python successfully you need a editor for writing your Python programs. Technical you could use everything where you can write text but it is not really purposeful.\nAn editor with syntax highlighting, code completion and debugging is very useful.\n\n\n\n\n\n\nTip\n\n\n\nRecommendation: Visual Studio Code\n\n\n\nOther editors:\n\nSpyder https://www.spyder-ide.org/\nPyCharm (JetBrains) https://www.jetbrains.com/products/compare/?product=pycharm&product=pycharm-ce\nJupyter Notebook https://jupyter.org/ https://code.visualstudio.com/docs/datascience/jupyter-notebooks\nJupyter Lab https://jupyter.org/ https://code.visualstudio.com/docs/datascience/jupyter-notebooks etc.\n\n\n\nPython extension for VS Code:\n\nPython from Microsoft,\nPylance from Microsoft\nand Jupyter from Microsoft (optional it is only needed if you want to use Jupyter Notebooks in VS Code)\n\nAlternatively you can use a Jupyter Notebook (*.ipynb) to execute code.\nWrite the code in a cell and execute it by pressing the run button.\nAdvantage of using Jupyter Notebooks: - The code can run cell by cell and the output is directly shown below the cell. - Further you can write text and equations in markdown cells. - Jupyter Notebooks can also handle different programming languages like Ror Julia. - Therefore it is very popular in the data science community.\nJupyter Notebooks can be used in VS Code, Jupyter Lab, Jupyter Notebook or Google Colab.\n\nIn this course all exercises are provided as Jupyter Notebooks.",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Installation Guide</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture0/InstallationGuide.html#test-your-setup",
    "href": "course/chapters/Introduction/Lecture0/InstallationGuide.html#test-your-setup",
    "title": "Installation Guide",
    "section": "6. Test your setup",
    "text": "6. Test your setup\n\nopen your editor\nopen a new file and save this file as helloworld.py\nwrite your first test program:\n\nprint(\"Hello World!\")\n\nexecute your program by using your IDE/Editor\nor using command line in the terminal (Linux/MacOS) / command prompt under Windows.\n\ncd /path/to/file\npython helloworld.py\nThe ouput should be: “Hello World!”.\nIf you are using Jupyter Notebook you can also write this code in a cell and execute it by pressing the run button.\n\n\n\n\n\n\nTip\n\n\n\nCongratulations You have successfully set up python!!\n\n\nAlternative to local installation: Google Colab {.unnumbered}\nGoogle Colab is a free cloud service provided by Google. It is based on Jupyter Notebooks and allows you to write and execute Python code in your browser.\n\nThe use of Google Colab needs a Google Account. Please read the Terms of Service and Privacy Policy",
    "crumbs": [
      "Essentials",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Installation Guide</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Basics.html",
    "href": "course/chapters/Python/Basics.html",
    "title": "Python Start",
    "section": "",
    "text": "Elemental Syntax\nThis will be a very fast and basic start into coding with Python.",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Start</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Basics.html#comands",
    "href": "course/chapters/Python/Basics.html#comands",
    "title": "Python Start",
    "section": "Comands",
    "text": "Comands\nEach line of code is a command. The computer reads the code from top to bottom and executes each command in order.\n\n\n\n\n\n\nExample - Hello World\n\n\n\nprint is a command that tells the computer to display the text that follows it.\n\n\nTry it out:\n\nprint(\"Hello World\")\n\nHello World\n\n\nIf you want to span a command over multiple lines you can use \\ or  if you are using parenthesis in your command you can directly use a new line.\n\n result = 1 + 2 + 3 + \\\n          7 + 8 + 9\n numbers = [\n     1, 2, 3,\n     4, 5, 6,\n     7, 8, 9\n ]",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Start</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Basics.html#indentation",
    "href": "course/chapters/Python/Basics.html#indentation",
    "title": "Python Start",
    "section": "Indentation",
    "text": "Indentation\nIn Python code blocks are not structured by brackets or semicolons like C/C++ or Java but by indentation. This means that the code inside a loop or a function is indented by a tab or four spaces.\n\n\n\n\n\n\nWarning\n\n\n\nIndentations are curcial in Python. If you don’t indent your code correctly, you will get an typical beginner error.\nPay attention to not mix tabs and spaces in your code.\n\n\n\n\n\n\n\n\nExample - Wrong Indentation\n\n\n\n\n\n\nTry it out:\n\nprint(\"correct indentation\")\n    print(\"wrong indentation\")\n\n\n  Cell In[3], line 2\n    print(\"wrong indentation\")\n    ^\nIndentationError: unexpected indent\n\n\n\n\nAll the lines in the block must have the same indentation:\n\n    print(\"correct indentation\") \n    print(\"correct indentation\")\n    print(\"correct indentation\")\n\ncorrect indentation\ncorrect indentation\ncorrect indentation",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Start</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Basics.html#error-messages",
    "href": "course/chapters/Python/Basics.html#error-messages",
    "title": "Python Start",
    "section": "Error messages",
    "text": "Error messages\nWhen you run a command that has an error, Python will print an error message.\nThe so called stack trace. It is a list of error messages that Python prints when an error occurs.\nIt gives you information about the error and the location of the error in your code.\nThe strack track is read from bottom to top.\nThe last line contains the error message and the line number where the error occured.\n\n\n\n\n\n\nTip\n\n\n\nOften the error messages are not very clear. You can search for the error message in the internet. Stackoverflow has a lot of answers to common errors. Or you can ask some AI e.g. ChatGPT.\n\n\n\n\n\n\n\n\nNote\n\n\n\nExample - Cryptic Error Message What does the error message tell you?\n\n\n\na = [1,2,3]\nprint(a[3])\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[5], line 2\n      1 a = [1,2,3]\n----&gt; 2 print(a[3])\n\nIndexError: list index out of range\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe error message tells you that you are trying to access an index that is out of range.",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Start</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Basics.html#comments",
    "href": "course/chapters/Python/Basics.html#comments",
    "title": "Python Start",
    "section": "Comments",
    "text": "Comments\nComments are important. They help you and others to understand your code.  You can use the ` symbol to write comments.\nDocstrings are used to document the code for example with pydoc. They are written using triple quotes `““” ““““`\n\n# This is a comment\n\n\"\"\"\nThis is a documentation.\nYou can document your code for example by pydoc\n\"\"\"\n\n'\\nThis is a documentation.\\nYou can document your code for example by pydoc\\n'",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Start</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Basics.html#if-statement",
    "href": "course/chapters/Python/Basics.html#if-statement",
    "title": "Python Start",
    "section": "if statement",
    "text": "if statement\n\nx = 0\nif x &lt; 0:\n    print(\"x &lt; 0\")\nelif x &gt; 0:\n    print(\"x &gt; 0\")\nelse:\n    print(\"x = 0\")\n\nx = 0",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Start</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Basics.html#breakcotinuepass",
    "href": "course/chapters/Python/Basics.html#breakcotinuepass",
    "title": "Python Start",
    "section": "break,cotinue,pass",
    "text": "break,cotinue,pass\n\nfor i in range(10):\n    if i == 5:\n        break\n    print(i)\n\n0\n1\n2\n3\n4\n\n\n\nfor i in range(10):\n    if i == 5:\n        continue\n    print(i)\n ```   \n\n```{python} \nfor i in range(10):\n    if i == 5:\n        pass\n    print(i)\n\n\n  File &lt;tokenize&gt;:5\n    ```\n    ^\nIndentationError: unindent does not match any outer indentation level",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Start</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Basics.html#for-loops",
    "href": "course/chapters/Python/Basics.html#for-loops",
    "title": "Python Start",
    "section": "For Loops",
    "text": "For Loops\n\nfor i in range(5): #from 0 to 4 \n    print(i)\n\n0\n1\n2\n3\n4\n\n\n\nfor i in range(1,10,2): # start 1, stop 10 excluded, step 2\n    print(i)\n\n1\n3\n5\n7\n9\n\n\n\nl = list(range(0,10))\n\n\nl\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\nfor i in l:  # using list\n    print(i)\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Start</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Basics.html#while-loops",
    "href": "course/chapters/Python/Basics.html#while-loops",
    "title": "Python Start",
    "section": "While Loops",
    "text": "While Loops\n\nx = 0\nwhile x  &lt; 4:\n    print(l[x])\n    x = x + 1\n\n0\n1\n2\n3\n\n\n\nprint(\"while loop with continue and break statement\")\nn = 0\nwhile(n &lt; 10):\n    n+=1\n    if n == 5:\n        continue\n    if n == 7:\n        print(\"The loop reached 7 and will break now.\")\n        break\n    print(n)\n\nwhile loop with continue and break statement\n1\n2\n3\n4\n6\nThe loop reached 7 and will break now.",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Start</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Basics.html#functions",
    "href": "course/chapters/Python/Basics.html#functions",
    "title": "Python Start",
    "section": "Functions",
    "text": "Functions\nFunctions are defined using the def keyword.  You can use the return keyword to return a value from a function.  The parameters of a function are defined in the parentheses.  Multiple parameters are separated by commas.  You can use default values for the parameter e.g. b=5.  Multiple return values are separated by commas.  They are stored in a tuple. \n\ndef summation(a,b=5):\n    return a+b, a-b\n\n\nsummation(4,2)\n\n(6, 2)\n\n\n\nsum, sub = summation(4)\nprint(sum)\nprint(sub)\n\n9\n-1\n\n\n\nx = 3\n\ndef multiple_return_value(x,a,b):\n    n = x+a\n    m = x-b\n    return [n,m]\nprint(multiple_return_value(x,5,10)[0],multiple_return_value(x,5,10)[1])\n\n8 -7",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Start</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Basics.html#style-guideline-for-writing-python-code",
    "href": "course/chapters/Python/Basics.html#style-guideline-for-writing-python-code",
    "title": "Python Start",
    "section": "Style guideline for writing python code",
    "text": "Style guideline for writing python code\nFor writing a readable code, it is important to follow a style guideline.  The most common style guideline for Python is PEP 8.",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Start</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/Intermediate.html",
    "href": "course/chapters/Python/Intermediate.html",
    "title": "Python Intermediate",
    "section": "",
    "text": "I/O (Input/Output)\nYou can use the print() function to print a message to the screen.  You can use the input() function to get input from the user.  You can use the open() function to open a file.  You can use the write() function to write to a file.  You can use the read() function to read from a file.  You can use the close() function to close a file.  You can use the with statement to open a file and automatically close it when you are done.  You can use the os module to work with files and directories.  You can use the sys module to work with command line arguments.  You can use the argparse module to work also with command line arguments. \nThis should print “Hello World!” to the console\n\nprint(\"Hello World!\")\n\nHello World!\n\n\nThis should ask the user to enter a number and print it to the console\n\nprint(input(\"Enter a number: \"))\n\n\n---------------------------------------------------------------------------\nStdinNotImplementedError                  Traceback (most recent call last)\nCell In[2], line 1\n----&gt; 1 print(input(\"Enter a number: \"))\n\nFile /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/ipykernel/kernelbase.py:1281, in Kernel.raw_input(self, prompt)\n   1279 if not self._allow_stdin:\n   1280     msg = \"raw_input was called, but this frontend does not support input requests.\"\n-&gt; 1281     raise StdinNotImplementedError(msg)\n   1282 return self._input_request(\n   1283     str(prompt),\n   1284     self._parent_ident[\"shell\"],\n   1285     self.get_parent(\"shell\"),\n   1286     password=False,\n   1287 )\n\nStdinNotImplementedError: raw_input was called, but this frontend does not support input requests.\n\n\n\nThis should write “Hello World!” to the file “file.txt”\n\nopen(\"file.txt\", \"w\").write(\"Hello World!\") \n\n12\n\n\nThis should read the file “file.txt” and print the content to the console\n\nprint(open(\"file.txt\").read()) \n\nHello World!\n\n\nThis should print “Hello World!” to the console without a newline\n\nprint(\"Hello World without newline.\", end=\"\") \nprint(\"Next print statement.\")\n\nHello World without newline.Next print statement.\n\n\nThis should read the file “file.txt” and print the content to the console\n\nwith open(\"file.txt\", \"r\") as file: print(file.read()) \n\nHello World!\n\n\n\n\nSystem\nThere are a lot of modules in Python to work with the system.  You can use the os module to work with files and directories.  You can use the sys module to work with command line arguments.  You can use the argparse module to work also with command line arguments. \nMost important functions are:  - os.getcwd() to get the current working directory.  - os.chdir() to change the current working directory.  - os.listdir() to list the files in a directory.  - os.mkdir() to create a directory.  - os.rmdir() to remove a directory.  - os.remove() to remove a file.  - os.rename() to rename a file.  - os.path.exists() to check if a file or directory exists.  - os.path.isfile() to check if a file exists.  - os.path.isdir() to check if a directory exists.  - os.path.join() to join two paths.  - os.path.basename() to get the base name of a path.  - os.path.dirname() to get the directory name of a path.  - os.path.abspath() to get the absolute path of a path.  - os.path.split() to split a path into a directory and a file.  - os.path.splitext() to split a path into a base name and an extension.  - os.path.getsize() to get the size of a file.  - os.path.getmtime() to get the modification time of a file. \n\nsys.argv to get the command line arguments. \nsys.exit() to exit the program. \nsys.stdin to read from the standard input. \nsys.stdout to write to the standard output. \nsys.stderr to write to the standard error. \nargparse.ArgumentParser() to create a parser. \nadd_argument() to add an argument to the parser. \nparse_args() to parse the command line arguments. \n\nThis should remove the file “file.txt”\n\nimport os\nos.remove(\"file.txt\")\n\nFor sys you can use the sys.argv to get the command line arguments.  sys.argv is a list of the command line arguments.  sys.argv[0] is the name of the script.  sys.argv[1] is the first argument. \n\nimport sys\nfirst_argument = sys.argv[1]\n\nFor more information about the sys module you can visit the official documentation.\nFor Argparse you can use the following code: For python scripts: You can use argparse to parse command line arguments.\n\nfrom argparse import ArgumentParser\n\nparser = ArgumentParser(description=\"This is a description.\")\nparser.add_argument(\"--arg1\", help=\"This is the first argument.\")\nparser.add_argument(\"---arg2\", help=\"This is the second argument.\")\nargs = parser.parse_args()\n\n\nAn exception has occurred, use %tb to see the full traceback.\n\nSystemExit: 2\n\n\n\n\nFor more information about Argparse you can visit the official documentation.\n\n\nPaths\nPay attention to the paths in your code. They are different defined in Windows and Linux. In Windows and macOS, you use backslashes / and in Linux, you use forward slashes \\.\nTo avoid this problem you can use the os or pathlib module to make your code platform independent.\n\nimport os\n\npath = os.path.join('folder1', 'folder2', 'folder3', 'data.dat')\nprint(path)\n\nfolder1/folder2/folder3/data.dat\n\n\n\nworking_dir = os.getcwd()\nprint(working_dir)\n\n/home/runner/work/PythonforChemists/PythonforChemists/course/chapters/Python\n\n\n\nfrom pathlib import Path\n\npath = Path('folder1') / 'folder2' / 'folder3' / 'data.dat'\nprint(path)\n\nfolder1/folder2/folder3/data.dat\n\n\n\nworking_dir = Path.cwd()\nprint(working_dir)\n\n/home/runner/work/PythonforChemists/PythonforChemists/course/chapters/Python",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python Intermediate</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/BasicsModules.html",
    "href": "course/chapters/Python/BasicsModules.html",
    "title": "Basic Modules",
    "section": "",
    "text": "Numpy and Pandas",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Basic Modules</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/BasicsModules.html#numpy",
    "href": "course/chapters/Python/BasicsModules.html#numpy",
    "title": "Basic Modules",
    "section": "Numpy",
    "text": "Numpy\n\nNumpy is the most important library for Python.\nThe standard data types in Python are very slow and not very efficient for data analysis.\nNumpy is based mainly on C an C++.\nThis allows Numpy to be faster than plain Python.\nWith Numpy a new data type is introduced numpy array.\nNumpy arrays are multidimensional arrays that are much faster than Python lists.\nThe libary also includes many mathematical functions and methods for linear algebra.\n\nMore information can found at the Numpy website.\nLoad the required libraries\n\nimport numpy as np\n\n\nNumpy Arrays\nAn array can be described as multidimensional lists. For example a matrix is a 2D array.\n\nmat = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(mat)\n\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n\n\nThe elements of an array can be accessed using the index of the element.\n\nprint(mat[0, 0])   # 1 element at row 0, column 0\n\n\nprint(mat[1, 2])  # 6 element at row 1, column 2\n\n\nprint(mat[:, 0])  # [1 4 7] all elements in column 0\n\n\nprint(mat[1, :])  # [4 5 6] all elements in row 1\n\n1\n6\n[1 4 7]\n[4 5 6]\n\n\n\nempty_mat = np.empty((3,3),dtype=float)\nprint(empty_mat)\n\n[[4.64300349e-310 0.00000000e+000 0.00000000e+000]\n [0.00000000e+000 0.00000000e+000 0.00000000e+000]\n [0.00000000e+000 0.00000000e+000 0.00000000e+000]]\n\n\n\nones_mat = np.ones((3, 3))\nprint(ones_mat)\n\n[[1. 1. 1.]\n [1. 1. 1.]\n [1. 1. 1.]]\n\n\n\nzeros_mat = np.zeros((3, 3))\nprint(zeros_mat)\n\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n\n\n\narr = np.arange(1, 10, 2) # an array from 1 to 10 with a step of 2\nprint(arr)\n\n[1 3 5 7 9]\n\n\n\narr2 = np.linspace(0,100,5) # an array from 0 to 100 with 5 elements\nprint(arr2)\n\n[  0.  25.  50.  75. 100.]\n\n\n\nrand_mat = np.random.rand(3,3) # a 3x3 matrix with random numbers between 0 and 1\nprint(rand_mat)\n\n[[0.46862819 0.79102411 0.39576119]\n [0.27916405 0.66523685 0.03336736]\n [0.75436484 0.85641896 0.23924887]]",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Basic Modules</span>"
    ]
  },
  {
    "objectID": "course/chapters/Python/BasicsModules.html#pandas",
    "href": "course/chapters/Python/BasicsModules.html#pandas",
    "title": "Basic Modules",
    "section": "Pandas",
    "text": "Pandas\n\nPandas is a library for data manipulation and analysis.\nIt is built on top of Numpy.\nWith Pandas you are working with dataframes and not with arrays like in Numpy.\nDataframes are two-dimensional labeled data structures with columns of potentially different types.\nIt is like a table in a database or a spreadsheet. Pandas has a lot of methods to manipulate dataframes.\nYou can select subsets of the data, filter, sort, group, merge, join, etc.\nYou can statistically analyze the data, export the data to different file formats, but also plot the data with the help of matplotlib.\n\nMore information can be found under Pandas website.\n\nimport pandas as pd\n\n\nPanda DataFrames",
    "crumbs": [
      "Python Crash Course",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Basic Modules</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture1/DataCollection.html",
    "href": "course/chapters/Introduction/Lecture1/DataCollection.html",
    "title": "Introduction to Data Science",
    "section": "",
    "text": "More information",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Data Science</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture1/DataCollection.html#what-is-data",
    "href": "course/chapters/Introduction/Lecture1/DataCollection.html#what-is-data",
    "title": "Introduction to Data Science",
    "section": "What is data?",
    "text": "What is data?\nData is a collection of\n\nnumbers\nwords\nmeasurements\nobservations",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Data Science</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture1/DataCollection.html#how-do-you-get-data",
    "href": "course/chapters/Introduction/Lecture1/DataCollection.html#how-do-you-get-data",
    "title": "Introduction to Data Science",
    "section": "How do you get data?",
    "text": "How do you get data?\nAt the beginning of every data science project, you need to collect data.\nData can be collected from various sources, such as:\n\nexperimental measurements\ncalculations and simulations\nsurveys\nexisting databases\nweb scraping\nAPIs\n\netc.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Data Science</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture1/DataCollection.html#how-do-you-store-the-data",
    "href": "course/chapters/Introduction/Lecture1/DataCollection.html#how-do-you-store-the-data",
    "title": "Introduction to Data Science",
    "section": "How do you store the data?",
    "text": "How do you store the data?",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Data Science</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture1/DataCollection.html#how-do-you-access-external-data",
    "href": "course/chapters/Introduction/Lecture1/DataCollection.html#how-do-you-access-external-data",
    "title": "Introduction to Data Science",
    "section": "How do you access external data?",
    "text": "How do you access external data?\nTo access data from exeternal sources, you can use different tools and libraries.\nFor example, if you want to access data from a chemical database e.g. \n\nMaterials Project, you can use the pymatgen library. (Requires API key, which can be obtained by registering on the website.)\nRCSB PDB Protein Data Bank, you can use the rcsb library.\nPubChem, you can use the pubchempy library.\n\n… and many more.\nIf you use APIs please read the documentation of the API to understand how to access the data. And make sure to respect the API usage policy and database terms of use.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Data Science</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture1/DataCollection.html#which-data-formats-do-you-use",
    "href": "course/chapters/Introduction/Lecture1/DataCollection.html#which-data-formats-do-you-use",
    "title": "Introduction to Data Science",
    "section": "Which data formats do you use?",
    "text": "Which data formats do you use?\nData can be stored in various data formats, such as: - Plain Text files (e.g. CSV, DAT, TXT) - Text files with structure (e.g. JSON, XML) - Spreadsheet files - Binary files (e.g. HDF5, Parquet, NetCDF,Feather, Pickle, npy, etc.) - Databases - chemical and molecular data formats (e.g. XYZ, CIF, PDB, etc.) - etc.\n\nPlain Text Files\nA text file often contains a header with the names of the columns and then the data in rows. Columns can be seperated by different delimiters (spaces, ,, ;, tabs, …).  For example, a file with data from an experiment could look like this:\nTime/s  Temperature/°C\n0         20\n10        21\n...     ...\n\n\n\nJSON or XML\nJSON stands for JavaScript Object Notation. Data is structured in a key-value format, so that both humans and machines can read it easily.  For example, a JSON file with the same data as above could look like this:\n{\n  \"data\": [\n    {\"Time\": 0, \"Temperature\": 20},\n    {\"Time\": 10, \"Temperature\": 21},\n    ...\n  ]\n}\nXML stands for Extensible Markup Language. It is also designed to be both human-readable and machine-readable.  For example, an XML file with the same data as above could look like this:\n&lt;data&gt;\n  &lt;measurement&gt;\n    &lt;Time&gt;0&lt;/Time&gt;\n    &lt;Temperature&gt;20&lt;/Temperature&gt;\n  &lt;/measurement&gt;\n  &lt;measurement&gt;\n    &lt;Time&gt;10&lt;/Time&gt;\n    &lt;Temperature&gt;21&lt;/Temperature&gt;\n  &lt;/measurement&gt;\n  ...\n\n\nBinary Files\nData is stored in a binary format and can be read with specific libraries. It is often used for large datasets, as it is more efficient than plain text files. The computer is able to read and write binary files faster than text files.  Some common binary file formats are:\n\nHDF5: Hierarchical Data Format, used for large datasets\nParquet: Columnar storage format, used for big data\nNetCDF: Network Common Data Form, array-orriented, often for geoscience data\nFeather: a fast column-based serialization for data frames, initially designed for R and Python, helps to share data between languages\nPickle: Python-specific format, used for serializing Python objects\nnpy: Numpy-specific format, used for saving numpy arrays\n\nHere is a list of comparison of binary file formats: Comparison of data serialization formats\n\n\nDatabases\nDatabases are designed for big data storage. The advantage of databases is that they can be queried and updated easily. There are different types of databases, such as: - SQL databases (e.g. SQLite, MySQL, PostgreSQL) - NoSQL databases (e.g. MongoDB) - Graph databases - Time series databases\n\n\nChemical and Molecular Data Formats\nThere are specific data formats for chemical and molecular data, such as:\n\nXYZ: Cartesian coordinates of atoms\nCIF: Crystallographic Information File, used for crystallographic data\nPDB: Protein Data Bank, used for protein structures\nMOL: Molecule file format, used for chemical structures\nSDF: Structure Data File, used for chemical structures\nSMILES: Simplified Molecular Input Line Entry System, used for chemical structures\nInChI: International Chemical Identifier, used for chemical structures\nnmrML: Nuclear Magnetic Resonance Markup Language, used for NMR data\nNMReDATA: Nuclear Magnetic Resonance Electronic Data Aggregation, used for NMR data\nJCAMP-DX: Joint Committee on Atomic and Molecular Physical Data, used for spectroscopy data\nmzML: Mass Spectrometry Markup Language, used for mass spectrometry data\naniml: Analytical Information Markup Language, used for analytical data\nFASTA: used for DNA and protein sequences\n\netc.\n\n\nOther Data Formats\n\nImages: Images can be stored in different formats, such as JPEG, PNG, TIFF, BMP, GIF, etc.\nAudio: Audio files can be stored in different formats, such as MP3, WAV, FLAC, etc.\nVideo: Video files can be stored in different formats, such as MP4, AVI, MOV, etc.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Data Science</span>"
    ]
  },
  {
    "objectID": "course/chapters/Introduction/Lecture1/DataCollection.html#what-type-of-data-do-you-have",
    "href": "course/chapters/Introduction/Lecture1/DataCollection.html#what-type-of-data-do-you-have",
    "title": "Introduction to Data Science",
    "section": "What type of data do you have?",
    "text": "What type of data do you have?\nNext what do you have to consider is the types of your data.\nDepending on the type of data analysis could be different.\n\nNumerical Data\nNumerical data is data that is expressed with numbers. It can be further divided into two types: - Discrete: Data that can only take certain values (e.g. integers) - Continuous: Data that can take any value within a certain range (e.g. real numbers)\nFor example, - measured temperature over time -&gt; continuous - number of chemical substances, which are measured -&gt; discrete\n\n\nCategorical Data\nCategorial means that data is divided into categories. It can be further divided into two types: - Ordinal: Data that has a specific order or ranking - Nominal: Data that has no specific order or ranking\nFor example, - blood type: nominal {A, B, AB, O} - chemical function group: nominal {alcohol, ketone, aldehyde, carboxylic acid, etc.} - purity of a substance: ordinal {low, medium, high} - hardness of a material: ordinal {soft, medium, hard}",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Data Science</span>"
    ]
  },
  {
    "objectID": "course/chapters/Basics/Lecture1/SimpleDataImport.html",
    "href": "course/chapters/Basics/Lecture1/SimpleDataImport.html",
    "title": "Simple Data Import",
    "section": "",
    "text": "Data Reading and Writing",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Simple Data Import</span>"
    ]
  },
  {
    "objectID": "course/chapters/Basics/Lecture1/SimpleDataImport.html#how-do-you-read-the-data",
    "href": "course/chapters/Basics/Lecture1/SimpleDataImport.html#how-do-you-read-the-data",
    "title": "Simple Data Import",
    "section": "How do you read the data?",
    "text": "How do you read the data?\nDepending on the data format, you can use different libraries to read the data.\n\nReading Plain Text Files\nYou can use the pandas or numpy library to read CSV files.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Simple Data Import</span>"
    ]
  },
  {
    "objectID": "course/chapters/Basics/Lecture1/SimpleDataImport.html#pandas",
    "href": "course/chapters/Basics/Lecture1/SimpleDataImport.html#pandas",
    "title": "Simple Data Import",
    "section": "Pandas",
    "text": "Pandas\nPandas is read function is quite fast and can read large files. The advantage is that different data types can be read in the same file. The reading functions return a DataFrame object.\nPandas has different functions to read different file formats.\n\npandas.read_csv() function is can read CSV files.\npandas.read_table() function is can read general delimiter files.\npandas.read_fwf() function is can read fixed-width files.\n\nMostly used function is pandas.read_csv() because you can specify the delimiter, header, and other options.\n\nimport pandas as pd\n\ndata = pd.read_csv(temperature_data)\ndata\n\n\n\n\n\n\n\n\ntime;temperature\n\n\n\n\n0\n1;303.073024218\n\n\n1\n2;302.951624807\n\n\n2\n3;302.831229733\n\n\n3\n4;302.73615227\n\n\n4\n5;302.708880354\n\n\n...\n...\n\n\n44635\n44636;296.102947663\n\n\n44636\n44637;296.173110138\n\n\n44637\n44638;296.140000813\n\n\n44638\n44639;296.169289777\n\n\n44639\n44640;296.287904152\n\n\n\n\n44640 rows × 1 columns\n\n\n\nThe data has a different delimiter than the default comma. You can specify the delimiter using the sep parameter.\n\ndata = pd.read_csv(temperature_data, sep=';')\ndata\n\n\n\n\n\n\n\n\ntime\ntemperature\n\n\n\n\n0\n1\n303.073024\n\n\n1\n2\n302.951625\n\n\n2\n3\n302.831230\n\n\n3\n4\n302.736152\n\n\n4\n5\n302.708880\n\n\n...\n...\n...\n\n\n44635\n44636\n296.102948\n\n\n44636\n44637\n296.173110\n\n\n44637\n44638\n296.140001\n\n\n44638\n44639\n296.169290\n\n\n44639\n44640\n296.287904\n\n\n\n\n44640 rows × 2 columns\n\n\n\nNow the data is read correctly. The header is already taken from the first row. If you want to specify the header, you can use the header parameter.\n\nimport pandas as pd\ndf = pd.read_csv('file.csv', header=None) # No header\ndf = pd.read_csv('file.csv', header=0) # Header is in the first row\ndf = pd.read_csv('file.csv', header=1) # Header is in the second row\n\n\ndata = pd.read_csv(temperature_data, sep=';', header=0)\ndata\n\n\n\n\n\n\n\n\ntime\ntemperature\n\n\n\n\n0\n1\n303.073024\n\n\n1\n2\n302.951625\n\n\n2\n3\n302.831230\n\n\n3\n4\n302.736152\n\n\n4\n5\n302.708880\n\n\n...\n...\n...\n\n\n44635\n44636\n296.102948\n\n\n44636\n44637\n296.173110\n\n\n44637\n44638\n296.140001\n\n\n44638\n44639\n296.169290\n\n\n44639\n44640\n296.287904\n\n\n\n\n44640 rows × 2 columns\n\n\n\nIf your data contains whitespace, you can use the skipinitialspace parameter to remove initial whitespaces.\n\ndata = pd.read_csv(temperature_dat, skipinitialspace=True, sep=\" \")\ndata\n\n\n\n\n\n\n\n\n1\n303.073024218\n\n\n\n\n0\n2\n302.951625\n\n\n1\n3\n302.831230\n\n\n2\n4\n302.736152\n\n\n3\n5\n302.708880\n\n\n4\n6\n302.647462\n\n\n...\n...\n...\n\n\n44634\n44636\n296.102948\n\n\n44635\n44637\n296.173110\n\n\n44636\n44638\n296.140001\n\n\n44637\n44639\n296.169290\n\n\n44638\n44640\n296.287904\n\n\n\n\n44639 rows × 2 columns\n\n\n\nNow the data has no header. You can specify the header using the names parameter.\n\ndata = pd.read_csv(temperature_dat, sep=' ', skipinitialspace=True,header=1,names=['t', 'T'])\n# important to set header=None, otherwise the first line is used as header\ndata\n\n\n\n\n\n\n\n\nt\nT\n\n\n\n\n0\n3\n302.831230\n\n\n1\n4\n302.736152\n\n\n2\n5\n302.708880\n\n\n3\n6\n302.647462\n\n\n4\n7\n302.513749\n\n\n...\n...\n...\n\n\n44633\n44636\n296.102948\n\n\n44634\n44637\n296.173110\n\n\n44635\n44638\n296.140001\n\n\n44636\n44639\n296.169290\n\n\n44637\n44640\n296.287904\n\n\n\n\n44638 rows × 2 columns\n\n\n\nYou see that also not .csv files can be read with the read_csv() function.\nThe read_csv() function has a lot of parameters. Look in the documentation. You can see which parameters you can set https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\nFor example, - delimiter parameter can be used to specify the delimiter instead of sep. Both are the same. Default is ,.\n\nheader parameter can be used to specify the header row. Default is inferred from the file.\nskipinitialspace parameter can be used to remove initial whitespaces. Default is False.\nnames parameter can be used to specify the column names.\nskiprows parameter can be used to skip rows at the beginning of the file.\nskipfooter parameter can be used to skip rows at the end of the file.\nnrows parameter can be used to read only a specific number of rows.\nusecols parameter can be used to read only specific columns.\ndtype parameter can be used to specify the data type of the columns.\nna_values parameter can be used to specify the missing values.\nkeep_default_na parameter can be used to specify if the default missing values should be kept. Default is True.\nna_filter parameter can be used to recognize missing values without NA or NaN values. Default is True.\ntrue_values parameter can be used to specify the values that should be recognized as True.\nfalse_values parameter can be used to specify the values that should be recognized as False.\nparse_dates parameter can be used to parse dates. Default is False.\n\nSome examples are:\n\ndata = pd.read_csv(temperature_data, sep=';', header=0, names=['t', 'T'], skiprows=1)\n\nNow the first row is skipped, only 44638 rows are read instead of 44639.\nMissing value examples:\n\ndata = pd.read_csv(temperature_nan_dat, sep=' ', skipinitialspace=True,header=None,names=['t', 'T'],  keep_default_na=True,na_filter=False)\nprint(data.loc[20:26]) #print some rows to see the NaN values\n\n     t              T\n20  21  302.020507467\n21  22               \n22  23  301.845408096\n23  24  301.833550446\n24  25  301.785933229\n25  26  301.846169501\n26  27  301.779994697\n\n\nIf the na_filteris set to False, the missing values are not recognized. But if it set on True, the missing values are recognized.\n\ndata = pd.read_csv(temperature_nan_dat, sep=' ', skipinitialspace=True,header=None,names=['t', 'T'],  keep_default_na=True,na_filter=True)\nprint(data.loc[20:26]) #print some rows to see the NaN values\n\n     t           T\n20  21  302.020507\n21  22         NaN\n22  23  301.845408\n23  24  301.833550\n24  25  301.785933\n25  26  301.846170\n26  27  301.779995",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Simple Data Import</span>"
    ]
  },
  {
    "objectID": "course/chapters/Basics/Lecture1/SimpleDataImport.html#numpy",
    "href": "course/chapters/Basics/Lecture1/SimpleDataImport.html#numpy",
    "title": "Simple Data Import",
    "section": "Numpy",
    "text": "Numpy\nNumpy has two main functions to read text files. - numpy.loadtxt() function is used to read text files. - numpy.genfromtxt() function is used to read text files with missing values.\nIn comparison to the pandas library, the numpy library is slower and can not read different data types in the same file. So you can not read a file with strings and numbers in the same file.\nIf you try to read a file with a header row, you will get an error.\n\nimport numpy as np\ndata = np.loadtxt(temperature_data, delimiter=';')\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nValueError: could not convert string to float: 'time'\n\nThe above exception was the direct cause of the following exception:\n\nValueError                                Traceback (most recent call last)\nCell In[10], line 2\n      1 import numpy as np\n----&gt; 2 data = np.loadtxt(temperature_data, delimiter=';')\n\nFile /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/numpy/lib/_npyio_impl.py:1395, in loadtxt(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\n   1392 if isinstance(delimiter, bytes):\n   1393     delimiter = delimiter.decode('latin1')\n-&gt; 1395 arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,\n   1396             converters=converters, skiplines=skiprows, usecols=usecols,\n   1397             unpack=unpack, ndmin=ndmin, encoding=encoding,\n   1398             max_rows=max_rows, quote=quotechar)\n   1400 return arr\n\nFile /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/numpy/lib/_npyio_impl.py:1046, in _read(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\n   1043     data = _preprocess_comments(data, comments, encoding)\n   1045 if read_dtype_via_object_chunks is None:\n-&gt; 1046     arr = _load_from_filelike(\n   1047         data, delimiter=delimiter, comment=comment, quote=quote,\n   1048         imaginary_unit=imaginary_unit,\n   1049         usecols=usecols, skiplines=skiplines, max_rows=max_rows,\n   1050         converters=converters, dtype=dtype,\n   1051         encoding=encoding, filelike=filelike,\n   1052         byte_converters=byte_converters)\n   1054 else:\n   1055     # This branch reads the file into chunks of object arrays and then\n   1056     # casts them to the desired actual dtype.  This ensures correct\n   1057     # string-length and datetime-unit discovery (like `arr.astype()`).\n   1058     # Due to chunking, certain error reports are less clear, currently.\n   1059     if filelike:\n\nValueError: could not convert string 'time' to float64 at row 0, column 1.\n\n\n\nYou can specify the header row using the skiprows parameter. If you want to skip one row, the skiprows=1 parameter is set at 1.\n\ndata = np.loadtxt(temperature_data, delimiter=';', skiprows=1)\ndata\n\narray([[1.00000000e+00, 3.03073024e+02],\n       [2.00000000e+00, 3.02951625e+02],\n       [3.00000000e+00, 3.02831230e+02],\n       ...,\n       [4.46380000e+04, 2.96140001e+02],\n       [4.46390000e+04, 2.96169290e+02],\n       [4.46400000e+04, 2.96287904e+02]], shape=(44640, 2))\n\n\nNow the data is read correctly. You can see that the data is read as a numpy array and not as a DataFrame. This can be a disadvantage if you want to use the data as a DataFrame but an advantage if you want to use numpy functions to process the data.\nIf you have data with whitespace, you do not need to specify the delimiterparamter because the default is whitespace.\n\ndata = np.loadtxt(temperature_dat)\ndata\n\narray([[1.00000000e+00, 3.03073024e+02],\n       [2.00000000e+00, 3.02951625e+02],\n       [3.00000000e+00, 3.02831230e+02],\n       ...,\n       [4.46380000e+04, 2.96140001e+02],\n       [4.46390000e+04, 2.96169290e+02],\n       [4.46400000e+04, 2.96287904e+02]], shape=(44640, 2))\n\n\ngenfromtxt() gives you more flexibility to read files with missing values.\nFirst using the loadtxt() function, you get an error because of the missing values.\n\ndata = np.loadtxt(temperature_nan_dat)\ndata\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 data = np.loadtxt(temperature_nan_dat)\n      2 data\n\nFile /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/numpy/lib/_npyio_impl.py:1395, in loadtxt(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\n   1392 if isinstance(delimiter, bytes):\n   1393     delimiter = delimiter.decode('latin1')\n-&gt; 1395 arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,\n   1396             converters=converters, skiplines=skiprows, usecols=usecols,\n   1397             unpack=unpack, ndmin=ndmin, encoding=encoding,\n   1398             max_rows=max_rows, quote=quotechar)\n   1400 return arr\n\nFile /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/numpy/lib/_npyio_impl.py:1046, in _read(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\n   1043     data = _preprocess_comments(data, comments, encoding)\n   1045 if read_dtype_via_object_chunks is None:\n-&gt; 1046     arr = _load_from_filelike(\n   1047         data, delimiter=delimiter, comment=comment, quote=quote,\n   1048         imaginary_unit=imaginary_unit,\n   1049         usecols=usecols, skiplines=skiplines, max_rows=max_rows,\n   1050         converters=converters, dtype=dtype,\n   1051         encoding=encoding, filelike=filelike,\n   1052         byte_converters=byte_converters)\n   1054 else:\n   1055     # This branch reads the file into chunks of object arrays and then\n   1056     # casts them to the desired actual dtype.  This ensures correct\n   1057     # string-length and datetime-unit discovery (like `arr.astype()`).\n   1058     # Due to chunking, certain error reports are less clear, currently.\n   1059     if filelike:\n\nValueError: the number of columns changed from 2 to 1 at row 22; use `usecols` to select a subset and avoid this error\n\n\n\nIf you try to read the file with an empty entrance at row 22, you wil get still an error with the genfromtxt() function.\n\ndata = np.genfromtxt(temperature_nan_dat)\ndata\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[14], line 1\n----&gt; 1 data = np.genfromtxt(temperature_nan_dat)\n      2 data\n\nFile /opt/hostedtoolcache/Python/3.10.16/x64/lib/python3.10/site-packages/numpy/lib/_npyio_impl.py:2333, in genfromtxt(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\n   2331 # Raise an exception ?\n   2332 if invalid_raise:\n-&gt; 2333     raise ValueError(errmsg)\n   2334 # Issue a warning ?\n   2335 else:\n   2336     warnings.warn(errmsg, ConversionWarning, stacklevel=2)\n\nValueError: Some errors were detected !\n    Line #22 (got 1 columns instead of 2)\n\n\n\nBut why? What do you think is the reason for the error?\n\n\n\n\n\n\nCaution\n\n\n\n\n\nThe reason is that the genfromtxt() function expects the same number of columns in each row. The delimiter is set default to whitespace. But if you have a missing value, the function expects a value. An error is raised because at row 22 the function is detecting only one column due to the missing value.\n\n\n\nHow can you solve this problem?\n\n\n\n\n\n\nCaution\n\n\n\n\n\nYou can NOT solve this problem with the genfromtxt() function if you have missing values and delimiter is whitespace. Either you have to fill the missing value with a value or you have to use the pandas library.\n\n\n\nIf you have not whitespace as delimiter, you can use the genfromtxt() function with missing values.\n\ndata = np.genfromtxt(temperature_nan_data,delimiter=';')\ndata[20:26] # print some rows to see the NaN values\n\narray([[ 21.        , 302.02050747],\n       [ 22.        ,          nan],\n       [ 23.        , 301.8454081 ],\n       [ 24.        , 301.83355045],\n       [ 25.        , 301.78593323],\n       [ 26.        , 301.8461695 ]])\n\n\nThe different parameters that can be set are for loadtxt() function:\n(see documentation https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html\n\ndelimiter parameter can be used to specify the delimiter. Default is whitespace.\nskiprows parameter can be used to skip rows at the beginning of the file.\nusecols parameter can be used to read only specific columns.\ndtype parameter can be used to specify the data type of the columns.\ncomments parameter can be used to specify the comment character. Default is #.\nmax_rows parameter can be used to read only a specific number of rows after skipping rows.\nunpack parameter can be used to unpack the columns, so each column is returned as a separate array.\n\nand for genfromtxt() function\n(see documentation https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html#numpy.genfromtxt)\n\ndelimiter parameter can be used to specify the delimiter. Default is whitespace.\nskip_header parameter can be used to skip rows at the beginning of the file.\nskip_footer parameter can be used to skip rows at the end of the file.\nusecols parameter can be used to read only specific columns.\ndtype parameter can be used to specify the data type of the columns.\ncomments parameter can be used to specify the comment character. Default is #.\nmax_rows parameter can be used to read only a specific number of rows after skipping rows.\nunpack parameter can be used to unpack the columns, so each column is returned as a separate array.\nmissing_values parameter can be used to specify which values should be recognized as missing values.\nfilling_values parameter can be used to specify the filling values for the missing values.\nusemask parameter can be used to return a masked array with missing values.\nnames parameter can be used to specify the column names. If names=True, the column names are read from the first row.\nreplace_space parameter can be used to replace spaces in the column names. Default is _.\n\netc.\n\n\n\n\n\n\nImportant\n\n\n\nThe pandas library is faster and more flexible than the numpy library. Choose wisely which library you want to use. It depends on the data format, the data type and what kind of processing you want to do.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Simple Data Import</span>"
    ]
  },
  {
    "objectID": "course/chapters/Basics/Lecture1/SimpleDataImport.html#exercises",
    "href": "course/chapters/Basics/Lecture1/SimpleDataImport.html#exercises",
    "title": "Simple Data Import",
    "section": "Exercises",
    "text": "Exercises",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Simple Data Import</span>"
    ]
  },
  {
    "objectID": "course/chapters/Basics/Lecture1/SimpleDataInspection.html",
    "href": "course/chapters/Basics/Lecture1/SimpleDataInspection.html",
    "title": "Simple Data Inspection",
    "section": "",
    "text": "Inspection of Data\nAfter you load your data you have to inspect it to:",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple Data Inspection</span>"
    ]
  },
  {
    "objectID": "course/chapters/Basics/Lecture1/SimpleDataInspection.html#inspection-of-data",
    "href": "course/chapters/Basics/Lecture1/SimpleDataInspection.html#inspection-of-data",
    "title": "Simple Data Inspection",
    "section": "",
    "text": "check if no data is consistent, no missing values\ncheck if the data is in the correct format\ncheck if the data is in the correct range\ncheck if the data is in the correct distribution\nget first insights into the data\n\n\nPandas\n\nOverview of the Data\nYou can use the head() function to get a quick overview of the first rows of the data.\n\nimport pandas as pd\n\ndata = pd.read_csv(temperature_data,sep=';')\ndata.head()\n\n\n\n\n\n\n\n\ntime\ntemperature\n\n\n\n\n0\n1\n303.073024\n\n\n1\n2\n302.951625\n\n\n2\n3\n302.831230\n\n\n3\n4\n302.736152\n\n\n4\n5\n302.708880\n\n\n\n\n\n\n\nThe describe() function gives you a quick overview of the data distribution.\n\ndata.describe()\n\n\n\n\n\n\n\n\ntime\ntemperature\n\n\n\n\ncount\n44640.000000\n44640.000000\n\n\nmean\n22320.500000\n297.937566\n\n\nstd\n12886.602345\n6.080222\n\n\nmin\n1.000000\n278.814670\n\n\n25%\n11160.750000\n293.842755\n\n\n50%\n22320.500000\n297.875930\n\n\n75%\n33480.250000\n301.879560\n\n\nmax\n44640.000000\n316.006103\n\n\n\n\n\n\n\nThe describefunction shows you the count, mean, standard deviation, minimum, 25%, 50%, 75% and maximum values of the data.\nIn this case, data has 44640 data points, The mean of the temperature is 298(6) K. The minimum temperature is 279 K and the maximum temperature is 316 K. Further the 25% quantile is 294 K, the 50% quantile is 298 K and the 75% quantile is 302 K. The measurement was taken from 1 to 44640 seconds which is 12 hours and 24 minutes. We suppose that is the correct time range which was to be expected.\nThis gives you a quick overview of the data distribution.\n\n\nMissing Data and Corrupted Data\nTo check if there is missing data in the data set you can use the isna() function.\n\ndata.isna().sum()\n\ntime           0\ntemperature    0\ndtype: int64\n\n\nNo missing data is found in this case.\nYou can check the data type using dtypes function to check if the data is in the correct format.\n\ndata.dtypes\n\ntime             int64\ntemperature    float64\ndtype: object\n\n\n\ndata.dtypes\n\ntime             int64\ntemperature    float64\ndtype: object\n\n\nYou see that time is an int64 and temperature is a float64. For the analysis, you might want to convert the time to a float64 as well.\n\ndata['time'] = data['time'].astype('float64')\n\n\ndata['time'] = data['time'].astype('float64')\ndata.dtypes\n\ntime           float64\ntemperature    float64\ndtype: object\n\n\nIf we have missing data we can use the fillna() function to fill the missing data with a specific value.\n\ndata.fillna(0)\n\n\n\n\n\n\n\n\ntime\ntemperature\n\n\n\n\n0\n1.0\n303.073024\n\n\n1\n2.0\n302.951625\n\n\n2\n3.0\n302.831230\n\n\n3\n4.0\n302.736152\n\n\n4\n5.0\n302.708880\n\n\n...\n...\n...\n\n\n44635\n44636.0\n296.102948\n\n\n44636\n44637.0\n296.173110\n\n\n44637\n44638.0\n296.140001\n\n\n44638\n44639.0\n296.169290\n\n\n44639\n44640.0\n296.287904\n\n\n\n\n44640 rows × 2 columns\n\n\n\n\ndata_missing = pd.read_csv(temperature_nan_data, header=None, skipinitialspace=True, sep=' ', names=['time', 'temperature'])\ndata_missing.head()\n\n\n\n\n\n\n\n\ntime\ntemperature\n\n\n\n\n0\n1\n303.073024\n\n\n1\n2\n302.951625\n\n\n2\n3\n302.831230\n\n\n3\n4\n302.736152\n\n\n4\n5\n302.708880\n\n\n\n\n\n\n\nOne value is missing in the temperature column. We fill it with 0.\nFirst let check where the data is missing.\n\ndata[data['temperature'].isna()]\n\n\n\n\n\n\n\n\ntime\ntemperature\n\n\n\n\n\n\n\n\n\ndata_missing[data_missing[‘temperature’].isna()]\nAt index 21 at time 22 s the temperature is missing.\n\n\n\n\n\n\nNote\n\n\n\nThe handling of missing data is a complex topic. First of all you have to check why the data is missing. Is it a measurement error, a data processing error etc.\nYou have to decide if you want to fill the missing data with a specific value, drop the row or column or interpolate the missing data. The decision depends on the data and the analysis you want to perform. Droping Data is always a delicate decision because you loose information. Sometimes it is not good scientific practice to drop data. For more information there a lot of research in this topic https://doi.org/10.1076/edre.7.4.353.8937\n\n\nThe time step can be estimated by the difference between the time steps of the previous and the next data point.\n\ndata['time'].diff()\n\n0        NaN\n1        1.0\n2        1.0\n3        1.0\n4        1.0\n        ... \n44635    1.0\n44636    1.0\n44637    1.0\n44638    1.0\n44639    1.0\nName: time, Length: 44640, dtype: float64\n\n\nAnd we can summarize it via:\n\ndata['time'].diff().value_counts()\n\ntime\n1.0    44639\nName: count, dtype: int64\n\n\n\ndata_missing['time'].diff().value_counts()\n\ntime\n1.0    44639\nName: count, dtype: int64\n\n\nget difference between temperature values\n\ndata_missing[10:30].diff()\n\n\n\n\n\n\n\n\ntime\ntemperature\n\n\n\n\n10\nNaN\nNaN\n\n\n11\n1.0\n0.000728\n\n\n12\n1.0\n-0.062319\n\n\n13\n1.0\n-0.130198\n\n\n14\n1.0\n-0.060203\n\n\n15\n1.0\n0.003234\n\n\n16\n1.0\n0.048911\n\n\n17\n1.0\n-0.042025\n\n\n18\n1.0\n0.021264\n\n\n19\n1.0\n0.033401\n\n\n20\n1.0\n0.054579\n\n\n21\n1.0\nNaN\n\n\n22\n1.0\nNaN\n\n\n23\n1.0\n-0.011858\n\n\n24\n1.0\n-0.047617\n\n\n25\n1.0\n0.060236\n\n\n26\n1.0\n-0.066175\n\n\n27\n1.0\n-0.080531\n\n\n28\n1.0\n-0.029080\n\n\n29\n1.0\n0.026428\n\n\n\n\n\n\n\nThe time step is constantly 1 second. The difference between the temperature of the previous and the next data point is at \\(~10^{-2}\\) order. We can assume that in this case the data is consistent enough and we can fill the missing data with the mean of the previous and the next data point.\n\ndata['temperature'].fillna((data['temperature'].shift() + data['temperature'].shift(-1))/2, inplace=True)\n\n\ndata_missing['temperature'].fillna((data_missing['temperature'].shift() + data_missing['temperature'].shift(-1))/2, inplace=True)\ndata_missing[20:25]\n\n\n\n\n\n\n\n\ntime\ntemperature\n\n\n\n\n20\n21\n302.020507\n\n\n21\n22\n301.932958\n\n\n22\n23\n301.845408\n\n\n23\n24\n301.833550\n\n\n24\n25\n301.785933\n\n\n\n\n\n\n\nNow can analysis or plot the data.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple Data Inspection</span>"
    ]
  },
  {
    "objectID": "course/chapters/Basics/Lecture1/SimplePlot.html",
    "href": "course/chapters/Basics/Lecture1/SimplePlot.html",
    "title": "Basic Data Visualization Techniques",
    "section": "",
    "text": "Basic Data Visualization Technique\nThe most popular data visualization libraries in Python is Matplotlib. Let`s start with the basic data visualization techniques using Matplotlib.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Basic Data Visualization Techniques</span>"
    ]
  },
  {
    "objectID": "course/chapters/Basics/Lecture1/SimplePlot.html#basic-data-visualization-technique",
    "href": "course/chapters/Basics/Lecture1/SimplePlot.html#basic-data-visualization-technique",
    "title": "Basic Data Visualization Techniques",
    "section": "",
    "text": "1. Generate some x-y data points.\n\n\n2. Plot the data points.\n\n\n\n\n\n\n\n\n\nTo add more graphs to the same figure, use plt.plot() multiple times before plt.show(). If you want to create a new figure, use plt.figure() before plt.plot().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3. Adjust the plot.\nThe plot() function takes the following arguments:\n\nx-axis data points\ny-axis data points\ncolor: hex, or color name (e.g., ‘red’, ‘blue’,‘black’), abbreviated (e.g., ‘r’, ‘b’,‘k’)\nlinestyle: ‘-’, ‘–’, ‘-.’, ‘:’ or “solid”, “dashed”, “dashdot”, “dotted”\nmarker: ‘o’, ‘x’, ‘+’, ’*‘, ’s’, ‘d’, ‘^’, ‘v’, ‘&gt;’, ‘&lt;’, ‘p’, ‘h’\nlinewidth - width of the line\nalpha - transparency of the line\nmarkerfacecolor - color of the marker face\nmarkersize - size of the marker\nlabel - label for the data points\n\nYou have to call plt.legend() to show the labels.\n\n\n\n\n\n\n\n\n\n\n\n4. Adust the figure\nThis plot figure can be adjusted by changing the figure size, title, labels, and so on.\n\nplt.xlabel(): Set the x-axis label of the current axis.\nplt.ylabel(): Set the y-axis label of the current axis.\nplt.title(): Set a title for the axes.\nplt.legend(): Place a legend on the axes.\nplt.grid(): Configure the grid lines.\nplt.xlim(): Get or set the x-limits of the current axes.\nplt.ylim(): Get or set the y-limits of the current axes.\nplt.xticks(): Get or set the current tick locations and labels of the x-axis.\nplt.yticks(): Get or set the current tick locations and labels of the y-axis.\nplt.figure(): Create a new figure.\nplt.show(): Display a figure.\n\n\n\n\n\n\n\n\n\n\n\n\nCreating multiple plots\nYou can create multiple plots in the same figure by using the subplot() function.\n\n\n\n\n\n\n\n\n\n\n\nText(0.5, 0.98, 'Right subfigure')\n\n\n\n\n\n\n\n\n\nLet`s try to create 4x3 subplots with specific adjustments.\n\nplt.subplots(4, 3): create 4x3 subplots\nfigsize=(3, 4): set the figure size to 3x4 inches\nsharex=True: all subplots share the x-axis\nsharey=True: all subplots share the y-axis\nconstraint_layout=True: automatically adjust the subplot parameters to give the specified padding around the subplots\ngridspec_kw={'hspace': 0.5, 'wspace': 0.5}: set the horizontal and vertical space between the subplots to 0.5 inches\n\nPlay with the code below to understand the different parameters:\n\nviewof figx = Inputs.range(\n  [1, 10], \n  {value: 5, step: 0.5, label: \"Figure x-size:\"}\n)\nviewof figy = Inputs.range(\n  [1, 10], \n  {value: 5, step: 0.5, label: \"Figure y-size:\"}\n)\nviewof constrained = Inputs.select([\"True\", \"False\"], {label: \"Select an option:\"})\nviewof dpi = Inputs.range(\n  [70, 100], \n  {value:75, step:5 , label: \"Dpi:\"}\n)\nviewof space_h = Inputs.range(\n  [0.1, 1], \n  {value: 0.5, step: 0.05, label: \"horizonatal space:\"}\n)\nviewof space_w = Inputs.range(\n  [0.1, 1], \n  {value: 0.5, step: 0.05, label: \"width space:\"}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#| edit: False\n#| runbutton: True\n#| input:\n#|   - figx\n#|   - figy\n#|   - constrained\n#|   - dpi\n#|   - space_w\n#|   - space_h\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nfig, ax = plt.subplots(3,2, figsize=(figx,figy), dpi=dpi, sharex=True, sharey=True, constrained_layout=constrained,gridspec_kw={'hspace': space_h, 'wspace': space_w})\n\nfor i in range(3):\n    for j in range(2):\n        ax[i,j].plot(x, y*(i+1)*(j+1))\n\nplt.show()",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Basic Data Visualization Techniques</span>"
    ]
  },
  {
    "objectID": "course/exercises/exercises/exercise1.html",
    "href": "course/exercises/exercises/exercise1.html",
    "title": "Exercise",
    "section": "",
    "text": "Lecture 1\nIn this exercise, we will repeat the first lecture of the course. We will:",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "course/exercises/exercises/exercise1.html#customizing-the-plots-ticks-labels-and-fontsize-very-low-difficulty",
    "href": "course/exercises/exercises/exercise1.html#customizing-the-plots-ticks-labels-and-fontsize-very-low-difficulty",
    "title": "Exercise",
    "section": "Customizing the Plots – Ticks, Labels and Fontsize (very low difficulty)",
    "text": "Customizing the Plots – Ticks, Labels and Fontsize (very low difficulty)\n\nExtract the data columns into separate arrays time and temperature (optional)\nSet up the plot by using the arrays time and temperature – color ‘k’ is black\nAdjust x- and y-range using plt.xlim(min,max) and plt.ylim(min,max)\nUse plt.xticks() to set the interval to 7200\n5 days \\(\\cdot\\) 24 hours \\(\\cdot\\) 60 min = 7200 min\nAdd labels using plt.xlabel(), plt.ylabel() and plt.title()\n(use fontsize = to adjust the size)\nUse plt.tick_params() to increase the size of the tick labels using labelsize = x\nAfter adjusting all settings, bring it home using plt.show()",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "course/exercises/exercises/exercise1.html#further-customization-adding-averages-low-difficulty",
    "href": "course/exercises/exercises/exercise1.html#further-customization-adding-averages-low-difficulty",
    "title": "Exercise",
    "section": "Further customization – adding averages (low difficulty)",
    "text": "Further customization – adding averages (low difficulty)\n\nChange the x-axis from minutes to days\ndays = time / 60 / 24\nControl the size of the plot using plt.figure(figsize = (x, y))\nAdd the average temperature using np.mean() and plt.achline()\nadd a running average using a window size of 1000 points\nusing np.convolve()\nUse different colors for the plots\nblack: color = ‘k’\nred: color = ‘r’\nblue: color = ‘b’\nAdd a legend by adding label = ‘my label’\nAdjust the axis range, labels and fontsize as before\nWhen done, again: plt.show()",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "course/exercises/exercises/exercise1.html#data-from-different-files-low-difficulty",
    "href": "course/exercises/exercises/exercise1.html#data-from-different-files-low-difficulty",
    "title": "Exercise",
    "section": "Data from Different Files (low difficulty)",
    "text": "Data from Different Files (low difficulty)\n\nTo import data from the other two files just re-use the commands from above.\nIn this example, it is sufficient to only extract the y-data.\nWe can even re-use the array days calculated above.\nWe plot all three temperature arrays and assign different colors.\nAdjust the axis range, labels and fontsize as before.\nPlace the legend into the upper left corner using plt.legend(loc=‘upper left’).\nWhen done, again: plt.show()\nOH NO! Experiment 3 is messed up!!",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "course/exercises/exercises/exercise1.html#data-from-different-files-in-different-subplots-low-difficulty",
    "href": "course/exercises/exercises/exercise1.html#data-from-different-files-in-different-subplots-low-difficulty",
    "title": "Exercise",
    "section": "Data from Different Files in Different subplots (low difficulty)",
    "text": "Data from Different Files in Different subplots (low difficulty)\n\nPlotting the data in different subplots of a single figure is very simple.\nDefine a figure fig with three subplots being ax1, ax2 and ax3.\nIn this example, the subplot is composed of 3 rows and 1 column.\nFor example plt.subplots(2,2) is composed of 2 rows and 2 columns.\nTo customize provide commands separately for each subplot.\nUse for-loops to apply the same settings to different plots.\nAssign axis labels individually.\nCareful: Commands for subplots are a bit different from just a normal plot.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "course/exercises/exercises/exercise1.html#sigmoid-curve-fitting",
    "href": "course/exercises/exercises/exercise1.html#sigmoid-curve-fitting",
    "title": "Exercise",
    "section": "Sigmoid Curve Fitting",
    "text": "Sigmoid Curve Fitting\nLet’s analyze how bad the situation is in experiment 3 is. To do this, we will fit a sigmoid curve to the data set using curve_fit() from the SciPy module scipy.optimize.\nIn our case the sigmoid function is given by:\n\\[\nT(t) = T_0 + \\Delta T \\frac{1}{1 + e^{-a (t - t_0)}}\n\\]\nwith the four fitting parameters being: - temperature baseline $ T_0 $, - the temperature increase $ T $ , - the growth rate $ a $ , - the time at the midpoint of the temperature increase $ t_0 $\nAfter fitting the curve, we can plot and overlay it with the original data for comparison.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "informations/license.html",
    "href": "informations/license.html",
    "title": "License",
    "section": "",
    "text": "MIT License\nCopyright (c) 2025 Stefanie Kröll\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "crumbs": [
      "Informations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>License</span>"
    ]
  },
  {
    "objectID": "informations/privacy.html",
    "href": "informations/privacy.html",
    "title": "Privacy Policy",
    "section": "",
    "text": "Hosting: GitHub Pages\nThis website does not collect, store or process any personally identifiable information and does not use cookies or other tracking technologies.\nThis website is hosted on GitHub Pages. GitHub says at",
    "crumbs": [
      "Informations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Privacy Policy</span>"
    ]
  },
  {
    "objectID": "informations/privacy.html#hosting-github-pages",
    "href": "informations/privacy.html#hosting-github-pages",
    "title": "Privacy Policy",
    "section": "",
    "text": "Github-Docs &gt; GitHub Pages &gt; Get started &gt; About GitHub Pages (https://docs.github.com/en/pages/getting-started-with-github-pages/about-github-pages):\n\n\n“When a GitHub Pages site is visited, the visitor’s IP address is logged and stored for security purposes, regardless of whether the visitor has signed into GitHub or not. For more information about GitHub’s security practices, see GitHub Privacy Statement”",
    "crumbs": [
      "Informations",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Privacy Policy</span>"
    ]
  },
  {
    "objectID": "informations/impressum.html",
    "href": "informations/impressum.html",
    "title": "Impressum",
    "section": "",
    "text": "This Data Analysis and Visualization for Chemists and Material Scientists tutorial is created by:\nStefanie Kröll, MSc\nUniversity of Innsbruck\nInstitute of General, Inorganic and Theoretical Chemistry\nUniversity of Innsbruck\nCenter for Chemistry and Biomedicine\nInnrain 80-82\nA-6020 Innsbruck\nAUSTRIA, Europe\n\nas part of the lecture course “VU Data Science and Visualization Primer for Chemists and Material Scientists” at UIBK\n\nContact Information\nEmail: s.kroell@student.uibk.ac.at\n\n\nResponsible for Content: Stefanie Kröll\nCopyright Notice: © 2025 Stefanie Kröll. All rights reserved.\n\nPrivacy Policy\nExternal Link Policy and Disclaimers",
    "crumbs": [
      "Informations",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Impressum</span>"
    ]
  },
  {
    "objectID": "informations/disclaimer.html",
    "href": "informations/disclaimer.html",
    "title": "Disclaimers",
    "section": "",
    "text": "Disclaimer:\nAll information provided on this website is offered “as is” without any warranties, expressed or implied, including, but not limited to, warranties of merchantability, fitness for a particular purpose, or non-infringement. While efforts are made to ensure the accuracy of the information, the website owner makes no guarantee of its correctness or completeness. Use the information at your own discretion and risk.\n\n\n\n\n\n\nExternal Link Policy\n\n\n\nIt is imperative to note that the external links present on this website are intended to serve as a reference point, providing insights into software programs, packages, tools and tutorials that can be utilised. The primary function of these links is to facilitate further information on the subject matter. It is crucial to acknowledge that the website author is not held responsible for the content or information found on external websites. Furthermore, the website author does not exercise any control over the content of such external websites. It is, therefore, incumbent upon the user to exercise due diligence when engaging with external links. The user uses the links at his own risk and is subject to the terms of services of the respective providers.",
    "crumbs": [
      "Informations",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Disclaimers</span>"
    ]
  }
]