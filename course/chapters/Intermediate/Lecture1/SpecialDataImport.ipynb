{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "---\n",
    "title: \"Special Data Import\"\n",
    "execute:\n",
    "    echo: true\n",
    "    eval: true\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get Data and how to store it? {.unnumbered}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can generate data via experiments, calculations, databanks, *etc.*. Data should be stored in a way that it is easy to access and analyze. Often there are used databases, spreadsheets, or text/csv files *ect.* . <br>\n",
    "A text file with data often contains a header with the names of the columns and then the data in rows. Columns can be seperated by different delimiters (`spaces`, `,`, `;`, `tabs`, ...). <br> For example, a file with data from an experiment could look like this:\n",
    "\n",
    "```plaintext\n",
    "Time [s]  Temperature [Â°C]\n",
    "0         20\n",
    "10        21\n",
    "...     ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read data from a file? {.unnumbered}\n",
    "\n",
    "In Python there are different ways to read data from a file. You can use the `open` function to open a file and then read the data line by line. You can also use libraries like `numpy`or  `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Biochemisches Grundpraktikum Julia Opitz Juni 2015 diechemiker.org\n",
      "\n",
      "['laenge_fragment_pb', 'Log(bp)', 'lauflaenge_pixel']\n",
      "[[23130.0, 4.364175633, 19.19], [9416.0, 3.97386645, 31.19], [6557.0, 3.816705184, 43.19], [4361.0, 3.639586087, 60.78], [2322.0, 3.365862215, 108.77], [2027.0, 3.306853749, 123.16], [910.0, 2.959041392, 192.74], [564.0, 2.751279104, 233.53], [540.0, 2.73239376, 235.13], [235.0, 2.371067862, 284.71], [166.0, 2.220108088, 301.51]]\n"
     ]
    }
   ],
   "source": [
    "# open the file for reading\n",
    "# data is from diechemiker.org (c) Julia Opitz 2015\n",
    "data_file = open('data/fragmentation.csv', 'r') \n",
    "#read all lines into a list\n",
    "fragments = data_file.readlines() \n",
    "# remove the first line from the list and store it as the header\n",
    "header = fragments.pop(0)\n",
    "print(header)\n",
    "# remove the second line from the list and store it as the names of the columns\n",
    "names = fragments.pop(0) \n",
    " # remove the newline character from the end of the line\n",
    "names = names.strip()\n",
    "# split the names into a list of values\n",
    "names = names.split(' ') \n",
    "print(names)\n",
    "# strip the newline character from each line\n",
    "data = [line.strip() for line in fragments]\n",
    "# split each line into a list of values\n",
    "data = [line.split(' ') for line in data] \n",
    "# convert each value to a float\n",
    "data = [[float(value) for value in line] for line in data] \n",
    "# close the file\n",
    "data_file.close()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data with Numpy {.unnumbered}\n",
    "There are two function `loadtxt` and `genfromtxt` to import data from a file. <br> \n",
    "The difference between the two functions is that `genfromtxt` can handle missing data and different data types. <br>\n",
    "More information under [https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html](https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html)  <br> or [https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fragment_runningsize_pb' 'Log(bp)' '' 'runningsize_pixel']\n",
      "[[2.31300000e+04 4.36417563e+00 1.91900000e+01]\n",
      " [9.41600000e+03 3.97386645e+00 3.11900000e+01]\n",
      " [6.55700000e+03 3.81670518e+00 4.31900000e+01]\n",
      " [4.36100000e+03 3.63958609e+00 6.07800000e+01]\n",
      " [2.32200000e+03 3.36586221e+00 1.08770000e+02]\n",
      " [2.02700000e+03 3.30685375e+00 1.23160000e+02]\n",
      " [9.10000000e+02 2.95904139e+00 1.92740000e+02]\n",
      " [5.64000000e+02 2.75127910e+00 2.33530000e+02]\n",
      " [5.40000000e+02 2.73239376e+00 2.35130000e+02]\n",
      " [2.35000000e+02 2.37106786e+00 2.84710000e+02]\n",
      " [1.66000000e+02 2.22010809e+00 3.01510000e+02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1682866/3354478495.py:2: UserWarning: Input line 1 contained no data and will not be counted towards `max_rows=1`.  This differs from the behaviour in NumPy <=1.22 which counted lines rather than rows.  If desired, the previous behaviour can be achieved by using `itertools.islice`.\n",
      "Please see the 1.23 release notes for an example on how to do this.  If you wish to ignore this warning, use `warnings.filterwarnings`.  This warning is expected to be removed in the future and is given only once per `loadtxt` call.\n",
      "  header = np.loadtxt('data/fragmentation.csv',\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('data/fragmentation.csv', delimiter=' ', skiprows=2)\n",
    "header = np.loadtxt('data/fragmentation.csv', \n",
    "                    delimiter=' ', max_rows=1, dtype=str)\n",
    "print(header)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header: \n",
      " ['fragment_runningsize_pb' 'Log(bp)' '' 'runningsize_pixel']\n",
      "data: \n",
      " [[2.31300000e+04 4.36417563e+00 1.91900000e+01]\n",
      " [9.41600000e+03 3.97386645e+00 3.11900000e+01]\n",
      " [6.55700000e+03 3.81670518e+00 4.31900000e+01]\n",
      " [4.36100000e+03 3.63958609e+00 6.07800000e+01]\n",
      " [2.32200000e+03 3.36586221e+00 1.08770000e+02]\n",
      " [2.02700000e+03 3.30685375e+00 1.23160000e+02]\n",
      " [9.10000000e+02 2.95904139e+00 1.92740000e+02]\n",
      " [5.64000000e+02 2.75127910e+00 2.33530000e+02]\n",
      " [5.40000000e+02 2.73239376e+00 2.35130000e+02]\n",
      " [2.35000000e+02 2.37106786e+00 2.84710000e+02]\n",
      " [1.66000000e+02 2.22010809e+00 3.01510000e+02]]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('data/fragmentation.csv', delimiter=' ', skip_header=2)\n",
    "# missing values are replaced with space\n",
    "header = np.genfromtxt('data/fragmentation.csv', delimiter=' ', \n",
    "                       max_rows=1, dtype=str, missing_values=' ') \n",
    "print(\"header: \\n\",header)\n",
    "print(\"data: \\n\",data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data with Pandas {.unnumbered}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `read_csv` function to import data from a file. The function can handle different file formats like csv or text based files. It can handle not valid values. <br>\n",
    "More information under [https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv). <br>\n",
    "Other panda read in functions are `read_excel`, `read_json`, `read_sql`, `read_html`, `read_clipboard`, `read_pickle`, `read_stata`, `read_feather`, `read_parquet`, `read_orc`, `read_sas`, `read_spss`, `read_gbq`, `read_hdf`, `read_stata`, `read_fwf`, `read_table`, `read_sql_query`, `read_sql_table`, `read_gbq`, `read_hdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first line is skipped and the second line is used as header\n",
    "#  (count from 0 because first line is skipped)\n",
    "data = pd.read_csv('data/fragmentation.csv', sep=' ', skiprows=1, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fragment_runningsize_pb   Log(bp)  Unnamed: 2  runningsize_pixel\n",
      "0                    23130  4.364176       19.19                NaN\n",
      "1                     9416  3.973866       31.19                NaN\n",
      "2                     6557  3.816705       43.19                NaN\n",
      "3                     4361  3.639586       60.78                NaN\n",
      "4                     2322  3.365862      108.77                NaN\n"
     ]
    }
   ],
   "source": [
    "print(data.head()) # print the first 5 rows"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
