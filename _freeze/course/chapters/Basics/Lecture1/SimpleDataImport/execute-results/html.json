{
  "hash": "54d637bd0737d4b59a76f3bd350f3f76",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Simple Data Import\"\nformat: live-html\nengine: jupyter\npyodide:\n  packages:\n    - matplotlib\n    - numpy\n    - seaborn\n    - pandas\n  resources:\n    - \"https://github.com/stkroe/PythonforChemists/blob/main/course/data/\"\ncode-links:\n      - text: \"Open in Colab\"\n        href: \"https://colab.research.google.com/github/stkroe/PythonForChemists/blob/main/course/chapters/Basics/SimpleDataImport.ipynb\"\n        icon: \"laptop\"\n--- \n\n\n\n\n\n\n\n# Data Reading and Writing {.unnumbered}\n\n\n## How do you read the data? {.unnumbered}\n\n\nDepending on the data format, you can use different libraries to read the data.\n\n\n### Reading Plain Text Files {.unnumbered}\n\nYou can use the `pandas`  or `numpy` library to read CSV files. \n\n\n\n## Pandas {.unnumbered}\nPandas is read function is quite fast and can read large files.\nThe advantage is that different data types can be read in the same file. \nThe reading functions return a DataFrame object. \n\nPandas has different functions to read different file formats.\n- `pandas.read_csv()` function is can read CSV files.\n- `pandas.read_table()` function is can read general delimiter files.\n- `pandas.read_fwf()` function is can read fixed-width files.\n\n\nMostly used function is\n`pandas.read_csv()` \nbecause you can specify the delimiter, header, and other options.\n\n\n\n\n\n\n\n```{pyodide}\nimport pandas as pd\ndata = pd.read_csv('temperatures.csv')\ndata\n```\n\n\n\n\n\n\nThe data has a different delimiter than the default `comma`. You can specify the delimiter using the `sep` parameter.\n\n\n\n\n\n\n\n\n```{pyodide}\ndata = pd.read_csv('temperatures.csv', sep=';')\ndata\n```\n\n\n\n\n\n\nNow the data is read correctly. The header is already taken from the first row. If you want to specify the header, you can use the `header` parameter.\n\n```python\nimport pandas as pd\ndf = pd.read_csv('file.csv', header=None) # No header\ndf = pd.read_csv('file.csv', header=0) # Header is in the first row\ndf = pd.read_csv('file.csv', header=1) # Header is in the second row\n```\n\n\n\n\n\n\n\n```{pyodide}\ndata = pd.read_csv('temperatures.csv', sep=';', header=0)\ndata\n```\n\n\n\n\n\n\nIf your data contains whitespace, you can use the `skipinitialspace` parameter to remove initial whitespaces.\n\n\n\n\n\n\n```{pyodide}\ndata = pd.read_csv('temperatures.dat', skipinitialspace=True, sep=\" \")\ndata\n```\n\n\n\n\n\n\nNow the data has no header. You can specify the header using the `names` parameter.\n\n\n\n\n\n\n\n```{pyodide}\ndata = pd.read_csv('temperatures.dat', sep=' ', skipinitialspace=True,header=1,names=['t', 'T'])\n# important to set header=None, otherwise the first line is used as header\ndata\n```\n\n\n\n\n\n\n\nYou see that also not `.csv` files can be read with the `read_csv()` function.\n\n\nThe `read_csv()` function has a lot of parameters. \nLook in the documentation. You can see which parameters you can set [https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n\nFor example,\n- `delimiter` parameter can be used to specify the delimiter instead of `sep`. Both are the same. Default is `,`.\n- `header` parameter can be used to specify the header row. Default is inferred from the file.\n- `skipinitialspace` parameter can be used to remove initial whitespaces. Default is `False`.\n- `names` parameter can be used to specify the column names.\n- `skiprows` parameter can be used to skip rows at the beginning of the file.\n- `skipfooter` parameter can be used to skip rows at the end of the file.\n- `nrows` parameter can be used to read only a specific number of rows.\n- `usecols` parameter can be used to read only specific columns.\n- `dtype` parameter can be used to specify the data type of the columns.\n- `na_values` parameter can be used to specify the missing values.\n- `keep_default_na` parameter can be used to specify if the default missing values should be kept. Default is `True`.\n- `na_filter` parameter can be used to recognize missing values without `NA` or `NaN` values. Default is `True`.\n- `true_values` parameter can be used to specify the values that should be recognized as `True`.\n- `false_values` parameter can be used to specify the values that should be recognized as `False`.\n- `parse_dates` parameter can be used to parse dates. Default is `False`.\n\n\n\n\nSome examples are:\n\n\n\n\n\n\n\n\n```{pyodide}\ndata = pd.read_csv('temperatures.csv', sep=';', header=0, names=['t', 'T'], skiprows=1)\n```\n\n\n\n\n\ndata now the first row is skipped, only 44638 rows are read instead of 44639\nMissing value examples:\n\n\n\n\n\n\n\n```{pyodide}\ndata = pd.read_csv('temperatures_nan.dat', sep=' ', skipinitialspace=True,header=None,names=['t', 'T'],  keep_default_na=True,na_filter=False)\nprint(data.loc[20:26]) print some rows to see the NaN values\n```\n\n\n\n\n\n\n\nIf the `na_filter`is set to `False`, the missing values are not recognized. But if it set on `True`, the missing values are recognized.\n\n\n\n\n\n\n```{pyodide}\ndata = pd.read_csv('temperatures_nan.dat', sep=' ', skipinitialspace=True,header=None,names=['t', 'T'],  keep_default_na=True,na_filter=True)\nprint(data.loc[20:26]) print some rows to see the NaN values\n```\n\n\n\n\n\n\n\n## Numpy {.unnumbered}\nNumpy has two main functions to read text files.\n- `numpy.loadtxt()` function is used to read text files.\n- `numpy.genfromtxt()` function is used to read text files with missing values.\n\nIn comparison to the `pandas` library, the `numpy` library is slower and can not read different data types in the same file.\nSo you can not read a file with strings and numbers in the same file.\n\n\n\nIf you try to read a file with a header row, you will get an error. \n\n\n\n\n\n\n\n```{pyodide}\nimport numpy as np\ndata = np.loadtxt('temperatures.csv', delimiter=';')\n```\n\n\n\n\n\n\nYou can specify the header row using the `skiprows` parameter.\nIf you want to skip one row, the `skiprows=1` parameter is set at `1`.\n\n\n\n\n\n\n\n```{pyodide}\ndata = np.loadtxt('temperatures.csv', delimiter=';', skiprows=1)\ndata\n```\n\n\n\n\n\n\nNow the data is read correctly. You can see that the data is read as a numpy array and not as a DataFrame. This can be a disadvantage if you want to use the data as a DataFrame but an advantage if you want to use numpy functions to process the data.\n\n\n\n\n\nIf you have data with whitespace, you do not need to specify the `delimiter`paramter because the default is whitespace.\n\n\n\n\n\n\n\n```{pyodide}\ndata = np.loadtxt('temperatures.dat')\ndata\n```\n\n\n\n\n\n\n`genfromtxt()` gives you more flexibility to read files with missing values. \n\n\nFirst using the `loadtxt()` function, you get an error because of the missing values. \n\n\n\n\n\n\n\n```{pyodide}\ndata = np.loadtxt('temperatures_nan.dat')\ndata\n```\n\n\n\n\n\n\nIf you try to read the file with an empty entrance at row 22, you wil get still an error with the `genfromtxt()` function. \n\n\n\n\n\n\n```{pyodide}\ndata = np.genfromtxt('temperatures_nan.dat')\ndata\n```\n\n\n\n\n\n\nBut why?\nWhat do you think is the reason for the error?\n\n\n::: {.callout-caution collapse=\"true\"}\nThe reason is that the `genfromtxt()` function expects the same number of columns in each row. The delimiter is set default to `whitespace`. But if you have a missing value, the function expects a value.\nAn error is raised because at row 22 the function is detecting only one column due to the missing value.\n:::\n\n\nHow can you solve this problem?\n\n::: {.callout-caution collapse=\"true\"}\nYou can **NOT** solve this problem with the `genfromtxt()` function if you have missing values and delimiter is whitespace.\nEither you have to fill the missing value with a value or you have to use the `pandas` library.\n:::\n\n\n\nIf you have not `whitespace` as delimiter, you can use the `genfromtxt()` function with missing values.\n\n\n\n\n\n\n\n```{pyodide}\ndata = np.genfromtxt('temperatures_nan.csv',delimiter=';')\ndata[20:26] # print some rows to see the NaN values\n```\n\n\n\n\n\n\nThe different parameters that can be set are for `loadtxt()` function:\n(see documentation [https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html](https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html) \n- `delimiter` parameter can be used to specify the delimiter. Default is whitespace.\n- `skiprows` parameter can be used to skip rows at the beginning of the file.\n- `usecols` parameter can be used to read only specific columns.\n- `dtype` parameter can be used to specify the data type of the columns.\n- `comments` parameter can be used to specify the comment character. Default is `#`.\n- `max_rows` parameter can be used to read only a specific number of rows after skipping rows.\n- `unpack` parameter can be used to unpack the columns, so each column is returned as a separate array.\nand for `genfromtxt()` function\n(see documentation [https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html#numpy.genfromtxt](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html#numpy.genfromtxt))\n- `delimiter` parameter can be used to specify the delimiter. Default is whitespace.\n- `skip_header` parameter can be used to skip rows at the beginning of the file.\n- `skip_footer` parameter can be used to skip rows at the end of the file.\n- `usecols` parameter can be used to read only specific columns.\n- `dtype` parameter can be used to specify the data type of the columns.\n- `comments` parameter can be used to specify the comment character. Default is `#`.\n- `max_rows` parameter can be used to read only a specific number of rows after skipping rows.\n- `unpack` parameter can be used to unpack the columns, so each column is returned as a separate array.\n- `missing_values` parameter can be used to specify which values should be recognized as missing values.\n- `filling_values` parameter can be used to specify the filling values for the missing values.\n- `usemask` parameter can be used to return a masked array with missing values.\n- `names` parameter can be used to specify the column names. If `names=True`, the column names are read from the first row.\n- `replace_space` parameter can be used to replace spaces in the column names. Default is `_`.\netc.\n\n\n\n\n::: {.callout-important}\nThe `pandas` library is faster and more flexible than the `numpy` library.\nChoose wisely which library you want to use.\nIt depends on the data format, the data type and what kind of processing you want to do.\n:::\n\n\n## Exercises {.unnumbered}\n\n",
    "supporting": [
      "SimpleDataImport_files"
    ],
    "filters": [],
    "includes": {}
  }
}